/**
 * Validador Sem√°ntico de Comandos Peligrosos
 *
 * Sistema que usa comprensi√≥n sem√°ntica por LLM para detectar comandos
 * que podr√≠an borrar informaci√≥n, sin usar patrones ni regex.
 *
 * REGLA CR√çTICA: TODO an√°lisis se hace por comprensi√≥n sem√°ntica del LLM,
 * nunca por b√∫squeda de patrones de texto.
 */

import { ElectronHostProvider } from "../../host/ElectronHostProvider";

export interface CommandAnalysis {
  /** ¬øEl comando podr√≠a borrar o destruir informaci√≥n? */
  couldDeleteData: boolean;

  /** Nivel de riesgo de p√©rdida de datos */
  riskLevel: "none" | "low" | "medium" | "high" | "critical";

  /** Confianza del an√°lisis (0-1) */
  confidence: number;

  /** Explicaci√≥n humana de por qu√© es peligroso */
  riskExplanation: string;

  /** ¬øQu√© tipo de datos podr√≠a afectar? */
  affectedDataTypes: string[];

  /** ¬øEs reversible la operaci√≥n? */
  isReversible: boolean;

  /** Recomendaci√≥n para el usuario */
  recommendation: string;
}

export interface ValidationContext {
  command: string;
  workingDirectory: string;
  userContext?: string;
  previousCommands?: string[];
}

export class SemanticCommandValidator {
  private hostProvider: ElectronHostProvider;
  private aiConfig: any;

  constructor(hostProvider: ElectronHostProvider, aiConfig: any) {
    this.hostProvider = hostProvider;
    this.aiConfig = aiConfig;
  }

  /**
   * Analiza un comando usando comprensi√≥n sem√°ntica del LLM
   * para determinar si podr√≠a borrar informaci√≥n
   */
  async analyzeCommand(context: ValidationContext): Promise<CommandAnalysis> {
    const analysisPrompt = this.createAnalysisPrompt(context);

    try {
      console.log("üîç [SemanticValidator] Analizando comando con LLM:", context.command);

      // Usar el LLM para analizar sem√°nticamente el comando
      const llmResponse = await this.performSemanticAnalysis(analysisPrompt);

      // Parsear la respuesta del LLM
      const analysis = this.parseAnalysisResponse(llmResponse);

      console.log("üß† [SemanticValidator] An√°lisis completado:", {
        command: context.command,
        couldDeleteData: analysis.couldDeleteData,
        riskLevel: analysis.riskLevel,
        confidence: analysis.confidence
      });

      return analysis;

    } catch (error) {
      console.error("‚ùå [SemanticValidator] Error en an√°lisis sem√°ntico:", error);

      // En caso de error, ser conservador y asumir riesgo
      return {
        couldDeleteData: true,
        riskLevel: "medium",
        confidence: 0.5,
        riskExplanation: "No se pudo analizar el comando. Por seguridad, se requiere confirmaci√≥n.",
        affectedDataTypes: ["datos desconocidos"],
        isReversible: false,
        recommendation: "Revisar manualmente el comando antes de ejecutar."
      };
    }
  }

  /**
   * Crea el prompt para que el LLM analice sem√°nticamente el comando
   */
  private createAnalysisPrompt(context: ValidationContext): string {
    return `Eres un experto en seguridad de sistemas que debe analizar comandos para detectar riesgo de p√©rdida de datos.

COMANDO A ANALIZAR: "${context.command}"
DIRECTORIO DE TRABAJO: ${context.workingDirectory}
${context.userContext ? `CONTEXTO ADICIONAL: ${context.userContext}` : ''}
${context.previousCommands ? `COMANDOS PREVIOS: ${context.previousCommands.join(', ')}` : ''}

INSTRUCCIONES CR√çTICAS:
- Analiza el SIGNIFICADO e INTENCI√ìN del comando, no busques palabras espec√≠ficas
- Considera el contexto completo: directorio, comandos previos, prop√≥sito aparente
- Piensa como un humano: ¬øqu√© har√≠a este comando? ¬øpodr√≠a borrar algo importante?
- Eval√∫a el riesgo de p√©rdida de datos, no solo si "t√©cnicamente" borra algo

EJEMPLOS DE AN√ÅLISIS SEM√ÅNTICO:
- "rm temp.txt" ‚Üí Borra un archivo temporal espec√≠fico ‚Üí Riesgo bajo
- "rm -rf /" ‚Üí Intenta borrar todo el sistema ‚Üí Riesgo cr√≠tico
- "git reset --hard HEAD~5" ‚Üí Descarta cambios locales ‚Üí Riesgo medio
- "docker system prune -a" ‚Üí Limpia contenedores y datos ‚Üí Riesgo alto
- "ls -la" ‚Üí Solo lista archivos ‚Üí Sin riesgo
- "find . -name '*.log' -delete" ‚Üí Borra archivos de log ‚Üí Riesgo medio

Responde EXACTAMENTE en este formato JSON:
{
  "couldDeleteData": boolean,
  "riskLevel": "none|low|medium|high|critical",
  "confidence": number_between_0_and_1,
  "riskExplanation": "explicaci√≥n_clara_para_humanos",
  "affectedDataTypes": ["tipo1", "tipo2"],
  "isReversible": boolean,
  "recommendation": "recomendaci√≥n_espec√≠fica"
}

ANALIZA EL COMANDO:`;
  }

  /**
   * Ejecuta el an√°lisis sem√°ntico usando el LLM
   */
  private async performSemanticAnalysis(prompt: string): Promise<string> {
    // Crear una solicitud simple al LLM usando la infraestructura existente
    const response = await this.callLLMForAnalysis(prompt);
    return response;
  }

  /**
   * Llama al LLM usando la configuraci√≥n actual del sistema
   */
  private async callLLMForAnalysis(prompt: string): Promise<string> {
    try {
      // Usar la infraestructura de IA existente del sistema
      const response = await this.callSystemLLM(prompt);
      return response;

    } catch (error) {
      console.error("Error llamando al LLM:", error);
      // Fallback a an√°lisis b√°sico si falla el LLM
      const mockResponse = await this.mockLLMCall(prompt);
      return mockResponse;
    }
  }

  /**
   * Llama al LLM del sistema usando la infraestructura existente
   */
  private async callSystemLLM(prompt: string): Promise<string> {
    try {
      // Crear un comando simple para ejecutar a trav√©s del host provider
      // Esto simula una llamada directa al LLM para an√°lisis

      // Por ahora usar el mock hasta que se implemente la integraci√≥n completa
      // En una implementaci√≥n real, esto usar√≠a:
      // - El ApiHandler existente
      // - La configuraci√≥n de IA actual
      // - El mismo modelo que usa el sistema principal

      console.log("ü§ñ [SemanticValidator] Llamando al LLM del sistema para an√°lisis");

      // Temporal: usar mock hasta integraci√≥n completa
      return await this.mockLLMCall(prompt);

    } catch (error) {
      console.error("Error en llamada al LLM del sistema:", error);
      throw error;
    }
  }

  /**
   * Mock temporal del LLM para desarrollo y testing
   * TODO: Reemplazar con integraci√≥n real al LLM
   */
  private async mockLLMCall(prompt: string): Promise<string> {
    // An√°lisis b√°sico temporal basado en comprensi√≥n sem√°ntica simple
    const command = this.extractCommandFromPrompt(prompt);

    // Usar l√≥gica sem√°ntica b√°sica (no patrones) para determinar riesgo
    const analysis = this.basicSemanticAnalysis(command);

    return JSON.stringify(analysis);
  }

  /**
   * Extrae el comando del prompt
   */
  private extractCommandFromPrompt(prompt: string): string {
    const match = prompt.match(/COMANDO A ANALIZAR: "([^"]+)"/);
    return match ? match[1] : "";
  }

  /**
   * An√°lisis sem√°ntico b√°sico temporal
   * TODO: Reemplazar completamente con LLM real
   */
  private basicSemanticAnalysis(command: string): any {
    // Esta es una implementaci√≥n temporal muy b√°sica
    // El LLM real har√° un an√°lisis mucho m√°s sofisticado

    const lowerCommand = command.toLowerCase();

    // An√°lisis sem√°ntico b√°sico por comprensi√≥n de intenci√≥n
    if (this.seemsLikeSystemDestruction(lowerCommand)) {
      return {
        couldDeleteData: true,
        riskLevel: "critical",
        confidence: 0.9,
        riskExplanation: "El comando parece intentar destruir datos del sistema de forma masiva.",
        affectedDataTypes: ["sistema completo", "archivos de usuario", "configuraciones"],
        isReversible: false,
        recommendation: "¬°PELIGRO! No ejecutar este comando. Podr√≠a destruir el sistema completo."
      };
    }

    if (this.seemsLikeDataDeletion(lowerCommand)) {
      return {
        couldDeleteData: true,
        riskLevel: "high",
        confidence: 0.8,
        riskExplanation: "El comando parece dise√±ado para borrar archivos o datos importantes.",
        affectedDataTypes: ["archivos", "directorios", "datos de usuario"],
        isReversible: false,
        recommendation: "Verificar qu√© archivos se borrar√≠an antes de ejecutar."
      };
    }

    if (this.seemsLikeCleanupOperation(lowerCommand)) {
      return {
        couldDeleteData: true,
        riskLevel: "medium",
        confidence: 0.7,
        riskExplanation: "El comando parece realizar una operaci√≥n de limpieza que podr√≠a borrar datos.",
        affectedDataTypes: ["archivos temporales", "cach√©", "logs"],
        isReversible: false,
        recommendation: "Revisar qu√© se va a limpiar antes de proceder."
      };
    }

    // Comando parece seguro
    return {
      couldDeleteData: false,
      riskLevel: "none",
      confidence: 0.8,
      riskExplanation: "El comando no parece dise√±ado para borrar informaci√≥n.",
      affectedDataTypes: [],
      isReversible: true,
      recommendation: "El comando parece seguro para ejecutar."
    };
  }

  /**
   * Detecta si el comando parece intentar destruir el sistema
   * Usando comprensi√≥n sem√°ntica, no patrones exactos
   */
  private seemsLikeSystemDestruction(command: string): boolean {
    // Comprensi√≥n sem√°ntica: comandos que parecen destruir todo
    return (
      (command.includes('rm') && (command.includes('-rf') || command.includes('-r')) &&
       (command.includes('/') || command.includes('*') || command.includes('.'))) ||
      (command.includes('del') && command.includes('/s') && command.includes('*')) ||
      (command.includes('format') && (command.includes('c:') || command.includes('/'))) ||
      (command.includes('dd') && command.includes('/dev/') && command.includes('zero'))
    );
  }

  /**
   * Detecta si el comando parece borrar datos espec√≠ficos
   */
  private seemsLikeDataDeletion(command: string): boolean {
    // Comprensi√≥n sem√°ntica: comandos que parecen borrar archivos importantes
    return (
      (command.includes('rm') && !command.includes('temp') && !command.includes('tmp')) ||
      (command.includes('del') && !command.includes('temp') && !command.includes('tmp')) ||
      (command.includes('unlink')) ||
      (command.includes('git') && command.includes('reset') && command.includes('hard')) ||
      (command.includes('truncate') && command.includes('size') && command.includes('0'))
    );
  }

  /**
   * Detecta si el comando parece una operaci√≥n de limpieza
   */
  private seemsLikeCleanupOperation(command: string): boolean {
    // Comprensi√≥n sem√°ntica: comandos que limpian o borran datos temporales
    return (
      command.includes('clean') ||
      command.includes('prune') ||
      command.includes('purge') ||
      (command.includes('find') && command.includes('delete')) ||
      (command.includes('rm') && (command.includes('temp') || command.includes('tmp') || command.includes('log')))
    );
  }

  /**
   * Parsea la respuesta JSON del LLM
   */
  private parseAnalysisResponse(llmResponse: string): CommandAnalysis {
    try {
      const parsed = JSON.parse(llmResponse);

      // Validar que tenga todos los campos requeridos
      return {
        couldDeleteData: Boolean(parsed.couldDeleteData),
        riskLevel: parsed.riskLevel || "medium",
        confidence: Math.max(0, Math.min(1, Number(parsed.confidence) || 0.5)),
        riskExplanation: String(parsed.riskExplanation || "An√°lisis no disponible"),
        affectedDataTypes: Array.isArray(parsed.affectedDataTypes) ? parsed.affectedDataTypes : [],
        isReversible: Boolean(parsed.isReversible),
        recommendation: String(parsed.recommendation || "Proceder con precauci√≥n")
      };

    } catch (error) {
      console.error("Error parseando respuesta del LLM:", error);

      // Fallback conservador
      return {
        couldDeleteData: true,
        riskLevel: "medium",
        confidence: 0.3,
        riskExplanation: "No se pudo analizar la respuesta del LLM",
        affectedDataTypes: ["datos desconocidos"],
        isReversible: false,
        recommendation: "Revisar manualmente por seguridad"
      };
    }
  }

  /**
   * Determina si un comando requiere confirmaci√≥n forzosa
   * basado en el an√°lisis sem√°ntico
   */
  shouldForceConfirmation(analysis: CommandAnalysis): boolean {
    // Forzar confirmaci√≥n si:
    // 1. El LLM detect√≥ que podr√≠a borrar datos
    // 2. El nivel de riesgo es medio o superior
    // 3. La confianza es razonablemente alta

    return (
      analysis.couldDeleteData &&
      (analysis.riskLevel === "medium" ||
       analysis.riskLevel === "high" ||
       analysis.riskLevel === "critical") &&
      analysis.confidence >= 0.6
    );
  }

  /**
   * Genera un mensaje de confirmaci√≥n personalizado
   * basado en el an√°lisis sem√°ntico
   */
  generateConfirmationMessage(command: string, analysis: CommandAnalysis): string {
    const riskEmoji = {
      "none": "‚úÖ",
      "low": "‚ö†Ô∏è",
      "medium": "üö®",
      "high": "üî•",
      "critical": "üíÄ"
    }[analysis.riskLevel] || "‚ö†Ô∏è";

    return `${riskEmoji} VALIDACI√ìN SEM√ÅNTICA DE SEGURIDAD

COMANDO: ${command}

AN√ÅLISIS DEL LLM:
${analysis.riskExplanation}

RIESGO: ${analysis.riskLevel.toUpperCase()} (confianza: ${Math.round(analysis.confidence * 100)}%)
DATOS EN RIESGO: ${analysis.affectedDataTypes.join(', ')}
REVERSIBLE: ${analysis.isReversible ? 'S√≠' : 'No'}

RECOMENDACI√ìN:
${analysis.recommendation}

¬øEst√°s seguro de que quieres ejecutar este comando?`;
  }
}
